{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Naive Bayes uses Bayes Theorem to find out the best hypothesis given data. Bayes Theorem states:\n",
    "$$P\\left(X \\ | \\ Y\\right)=\\frac{P\\left(Y \\ | \\ X\\right)\\cdot P\\left(X\\right)}{P\\left(Y\\right)}$$\n",
    "\n",
    "Where,\n",
    "\n",
    "1. P(X|Y) is the posterior probability\n",
    "2. P(Y|X) is the probability assuming that the hypothesis were true. \n",
    "3. P(X) is the prior probability which is irrespective of data. \n",
    "4. P(Y) is probability of the data, irrespective of hypothesis. \n",
    "\n",
    "Once we have these probabilities, in the end we choose the hypothesis with the maximum probability. This is also called as __Maximum A Posteriori (MAP) Estimation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes is called \"Naive\" ?\n",
    "\n",
    "Naive Bayes classifier assumes that the presence (or absence) of a particular feature of a class is unrelated to the presence (or absence) of any other feature, given the class variable. For example, a fruit may be considered to be an apple if it is red, round, and about 4\" in diameter. Even if these features depend on each other or upon the existence of the other features, a naive Bayes classifier considers all of these properties to independently contribute to the probability that this fruit is an apple.\n",
    "\n",
    "While calculating P(Y|X) we simply multiply the terms, eg P(Y0, Y1, Y2 | X) = P(Y0|X) \\* P(Y1|X) \\* P(Y2|X). Here we assume independce between Y0, Y1 etc. which may or may not be true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "While calculating P(Y|X) we assume the features are categorical, so we can count things. But if there are real valued numbers, we instead take the pdf of the number. We fit a gaussian to the given dataset and take it's pdf instead of P(Y|X)\n",
    "\n",
    "$$P\\left(X \\ | \\ Y\\right)=\\frac{PDF\\left(Y \\ \\vert \\ X \\right)\\cdot P\\left(X\\right)}{PDF\\left(Y\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative vs Discriminative Model\n",
    "\n",
    "Genrative models: they try to mimic the underlying process which generated the dataset. \n",
    "\n",
    "Disriminative models: these models don't have anything with how the data is generated, they will simply classify things. \n",
    "\n",
    "For more read: https://stackoverflow.com/a/879591/1878563\n",
    "\n",
    "Naive Bayes is a discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
