{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "CNNs are Neural Networks that are used to classify images. They do so by using `filters` and `convolutions`. `filters` are the weights in CNNs. They're a column vector in NNs(e.g. hidden layer with 3 nodes), and a matrix in CNNs (3x3 filter). One more way how they differ from ordinary NNs is they use the idea of shared weights. \n",
    "\n",
    "### Shared Weights\n",
    "CNNs achieve translational invarince using shared weights. The basic idea is: if a filter detects a horizontal line, then it is intuitive for it to detect the line anywhere in the image irrespective of the location. Hence, there is no need to learn how to detect a line at a different location again and again. Also: __it enormously decreases the number of parameters to learn__. In a normal NN, it would have one weight for every pixel in the image which are too many hyper parameters.  \n",
    "\n",
    "Steps:\n",
    "1. Convolution\n",
    "2. Max Pooling\n",
    "3. ReLU\n",
    "4. Flattening\n",
    "5. Full Connection\n",
    "\n",
    "\n",
    "### Convolution layer\n",
    "For an image, we create a filter/kernel (from the same image) that performs element wise multiplication (convolution). Hence using this we can detect edges, and various other information about the image. The convolution matrix is initially initialised with random zero-centered numbers. Later it will automatically learn to figure out various aspects of the image. \n",
    "\n",
    "Important thing to remember: depth of filter in current layer equals the number of channels in previous layer. \n",
    "\n",
    "### Interpreting Convolutions\n",
    "Initial convolution layers learn basic things like horizontal lines, vertical lines, small shapes. And as the layers go on increasing they learn more and more high level features. Like a facial recognition model will learn basic lines in the initial layers, then learn nose, eyes, etc in the next layers, then faces in the final layers. \n",
    "\n",
    "### Filters\n",
    "Filters are the weights in CNNs. These filters have depth, another hyperparameter. One filter is a 2D array which can be interpreted as something that learn a shape. We can create an array of such filters thus adding a depth to it. Each filter learns a different element: one might learn horizontal lines, one might learn a basic circle shape, etc. \n",
    "\n",
    "\n",
    "### Padding\n",
    "In padding we add an extra layer of 0s accross the dimension so that adding multiple convolutions won't shrink the dimensions quickly. \n",
    "\n",
    "\n",
    "### Output Dimensions\n",
    "The output dimensions after padding are:\n",
    "\n",
    "$$W_0 = \\frac{W_i - F + 2P}{2}$$\n",
    "\n",
    "\n",
    "$$H_0 = \\frac{H_i - F + 2P}{2}$$\n",
    "\n",
    "Where, \n",
    "W_i is the input width, H_i is input height, F is filter size (it's symmetric), and P is the padding\n",
    "\n",
    "### Structuring (selecting filter size and depth)\n",
    "It is suggested that the filter size should be bigger in the initial layers, and depth should be smaller. For subsequent layers, you should be reducing the filter size and increasing the depth. That's because the final layers are high level representations so increase the depth in the final layers means more high level features will be learned. The size should generally be a multiple of 2. \n",
    "\n",
    "### Pooling\n",
    "Pooling is used for following reasons:\n",
    "1. Translational Invariance: we don't care where the face is for a facial classifier. \n",
    "2. Reduction in number of parameters, while respecting the spatial ascept. \n",
    "3. Reduce overfitting. \n",
    "\n",
    "There are couple of ways of pooling: mean, max. Max pooling is most commonly used with 2x2 ksize and 2 stride. There are also overlapping ksizes in pooling. \n",
    "\n",
    "Recently, pooling is not much used because:\n",
    "1. Datasets are so diverse, we're more concerned about underfitting, than overfitting. \n",
    "2. Dropout is a much better regularizer. \n",
    "3. Downsampling image results in information loss. \n",
    "\n",
    "### ReLU (Activation Function)\n",
    "This operation add non-linearity in the network. It is a computationally efficient activation function and has many advantages over other. \n",
    "\n",
    "### Flattening\n",
    "This operation simply flattens the matrix, that is, converts the matrix into single column by appending all the rows below one another. \n",
    "\n",
    "### Fully connected layer\n",
    "Once we have the flattened input, imagine this step as creating a neural network with hidden layers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Layer in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# convolutional filter\n",
    "filter_width = 5\n",
    "filter_height = 5\n",
    "\n",
    "# input image\n",
    "# first element in shape is batch_size which needn't be provided\n",
    "input_image = tf.placeholder(tf.float32, shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([filter_height, filter_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# apply convolution\n",
    "conv = tf.nn.conv2d(input_image, weights, strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "conv = tf.nn.bias_add(conv, bias)\n",
    "\n",
    "# max pooling\n",
    "conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "# activation\n",
    "conv = tf.nn.relu(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classifier in Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# 1. Convolution\n",
    "# filters = number of filters\n",
    "# kernel size is the size of MxM matrix of filter\n",
    "# stride is the stride matrix size\n",
    "# input shape (row, cols, dims) note this is reverse for Theano backend\n",
    "classifier.add(Convolution2D(filters=32, kernel_size=3, strides=3, input_shape=(64, 64, 3), activation='relu'))\n",
    "\n",
    "# 2. Pooling\n",
    "# pool size is the matrix dimension of the pooling matrix \n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 3. Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# 4. Fully connected layer\n",
    "# Rule of thumb for picking the output dimension is to pick the\n",
    "# mean of number of output and number of input.\n",
    "# Good practice: to pick a power of 2\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# 5. Output layer\n",
    "# for binary classification: sigmoid activation\n",
    "# more than 3 classes: softmax\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# import images and augment\n",
    "# Data Augmentation will generate more images with following changes:\n",
    "# 1. Rescale\n",
    "# 2. Shearing\n",
    "# 3. Random Zooming\n",
    "# 4. Horizontal flipping\n",
    "# This will basically give us additional data for training \n",
    "# Furthermore, it will reduce overfitting\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "\n",
    "# target size is the size of the image expected by your model\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch = 8000,\n",
    "    epochs = 25,\n",
    "    validation_data = test_set,\n",
    "    validation_steps = 2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
