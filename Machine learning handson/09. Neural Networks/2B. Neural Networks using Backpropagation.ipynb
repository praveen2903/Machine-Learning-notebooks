{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'Theta1', 'Theta2'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat(\"machine_learning_andrewng/ex4data1.mat\")\n",
    "weights = loadmat(\"machine_learning_andrewng/ex3weights.mat\")\n",
    "print(data.keys())\n",
    "print(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y = data['y']\n",
    "y = pd.get_dummies(y.ravel()).values\n",
    "theta1_loaded = weights[\"Theta1\"]\n",
    "theta2_loaded = weights[\"Theta2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from time import time\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"Creates Neural Network for MNIST dataset.\"\"\"\n",
    "    def __init__(self, hidden_size=25, output_size=10, lambda_=0):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.thetas = None\n",
    "        self.lambda_ = lambda_\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.input_size = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten(arr1, arr2):\n",
    "        return np.r_[arr1.flatten(), arr2.flatten()]\n",
    "    \n",
    "    def set_params(self, *thetas):\n",
    "        self.thetas = self.flatten(*thetas)\n",
    "\n",
    "    def unflatten(self, arr):\n",
    "        theta1 = arr[:self.hidden_size * (self.input_size + 1)]\n",
    "        theta1 = theta1.reshape(self.hidden_size, self.input_size + 1)\n",
    "        theta2 = arr[self.hidden_size * (self.input_size + 1):]\n",
    "        theta2 = theta2.reshape(self.output_size, self.hidden_size + 1)\n",
    "        return theta1, theta2\n",
    "\n",
    "    def init_random_thetas(self, epsilon=0.12):\n",
    "        theta1 = np.random.rand(self.hidden_size, self.input_size + 1) \\\n",
    "                 * 2 * epsilon - epsilon\n",
    "        theta2 = np.random.rand(self.output_size, self.hidden_size + 1) \\\n",
    "                 * 2 * epsilon - epsilon\n",
    "        return self.flatten(theta1, theta2)\n",
    "\n",
    "    def sigmoid_prime(self, z):\n",
    "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
    "\n",
    "    def cross_entropy(self, thetas=None):\n",
    "        if thetas is None:\n",
    "            theta1, theta2 = self.unflatten(self.thetas)\n",
    "        else:\n",
    "            theta1, theta2 = self.unflatten(thetas)\n",
    "        m = self.X.shape[0]\n",
    "        y_pred = self.forward_pass(thetas)\n",
    "        positive_loss = np.sum(np.multiply(self.y, np.log(y_pred)).flatten())\n",
    "        negative_loss = np.sum(np.multiply((1 - self.y), np.log(1 - y_pred))\n",
    "                               .flatten())\n",
    "        regularization = (self.lambda_ / (2 * m)) \\\n",
    "                         * (np.sum(theta1.flatten() ** 2)\n",
    "                            + np.sum(theta2.flatten() ** 2))\n",
    "        J = - (1 / m) * (positive_loss + negative_loss) + regularization\n",
    "        return J\n",
    "\n",
    "    def forward_pass(self, thetas=None, elaborate=False):\n",
    "        if thetas is None:\n",
    "            theta1, theta2 = self.unflatten(self.thetas)\n",
    "        else:\n",
    "            theta1, theta2 = self.unflatten(thetas)\n",
    "        a1 = np.c_[np.ones(self.X.shape[0]), self.X]\n",
    "        z2 = theta1.dot(a1.T)                   # 25x401 * 401x5000 = 25x5000\n",
    "        a2 = self.sigmoid(z2.T)                 # 5000x25\n",
    "        a2 = np.c_[np.ones(a2.shape[0]), a2]    # 5000x26\n",
    "        z3 = theta2.dot(a2.T)                   # 10x26 * 26x5000 = 10x5000\n",
    "        a3 = self.sigmoid(z3.T)                 # 5000x10\n",
    "        if elaborate:\n",
    "            return (a1, a2, a3), (z2, z3)\n",
    "        return a3\n",
    "\n",
    "    def backward_pass(self, thetas=None):\n",
    "        if thetas is None:\n",
    "            theta1, theta2 = self.unflatten(self.thetas)\n",
    "        else:\n",
    "            theta1, theta2 = self.unflatten(thetas)\n",
    "        (a1, a2, y_pred), (z2, z3) = self.forward_pass(thetas, elaborate=True)\n",
    "        delta3 = np.multiply((y_pred - self.y), self.sigmoid_prime(z3.T))\n",
    "        theta2_grad = a2.T.dot(delta3)\n",
    "        theta2_grad = theta2_grad.T\n",
    "        # theta2_grad.shape is now same as theta2.shape\n",
    "        delta2 = np.multiply(delta3.dot(theta2[:, 1:]), self.sigmoid_prime(z2.T))\n",
    "        theta1_grad = a1.T.dot(delta2)\n",
    "        theta1_grad = theta1_grad.T\n",
    "        return self.flatten(theta1_grad, theta2_grad)\n",
    "\n",
    "    def gradient_descent(self, X, y, n_epochs=1000, alpha=0.001):\n",
    "        self.thetas = self.init_random_thetas()\n",
    "        theta1, theta2 = self.unflatten(self.thetas)\n",
    "        \n",
    "        for i in range(1, n_epochs+1):\n",
    "            cost = self.cross_entropy()\n",
    "            print(\"\\rIteration: {0} Cost: {1}\".format(i, cost), end=\"\")\n",
    "            theta1_grad, theta2_grad = self.unflatten(self.backward_pass())\n",
    "            theta1 = theta1 - alpha * theta1_grad\n",
    "            theta2 = theta2 - alpha * theta2_grad\n",
    "            self.thetas = self.flatten(theta1, theta2)\n",
    "        print()\n",
    "        \n",
    "    def fmin_unc(self, X, y, **params):\n",
    "        self.thetas = self.init_random_thetas()\n",
    "        res = minimize(self.cross_entropy, self.thetas, jac=self.backward_pass,\n",
    "                       method=\"tnc\", options=params)\n",
    "        print(res)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if y.shape[1] != self.output_size:\n",
    "            raise ValueError(\"Number of columns in y ({0}) are != to number \"\n",
    "                             \"of output neurons ({1})\"\n",
    "                             .format(y.shape[1], self.output_size))\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.input_size = X.shape[1]\n",
    "    \n",
    "    def train(self, method=\"gradient_descent\", **params):\n",
    "        start_time = time()\n",
    "        if method == \"gradient_descent\":\n",
    "            self.gradient_descent(X, y, **params)\n",
    "        else:\n",
    "            self.fmin_unc(X, y, **params)\n",
    "        print(\"Training time: {0:.2f} secs\".format(time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using Gradient Descent\n",
      "Iteration: 1000 Cost: 0.4537310003354624\n",
      "Training time: 363.20 secs\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(hidden_size=25, output_size=10)\n",
    "nn.fit(X, y)\n",
    "print(\"Training using Gradient Descent\")\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using Newton's Conjugate Gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uzumaki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: divide by zero encountered in log\n",
      "/home/uzumaki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 0.20524144916151227\n",
      "     jac: array([ 0.36232879,  0.        ,  0.        , ...,  0.01946602,\n",
      "        0.00914086,  0.08010389])\n",
      " message: 'Linear search failed'\n",
      "    nfev: 416\n",
      "     nit: 27\n",
      "  status: 4\n",
      " success: False\n",
      "       x: array([ 0.30034467,  0.10823752,  0.04806109, ..., -1.10953355,\n",
      "       -2.55846507,  1.88672616])\n",
      "Training time: 80.30 secs\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(hidden_size=25, output_size=10)\n",
    "nn.fit(X, y)\n",
    "print(\"Training using Newton's Conjugate Gradient\")\n",
    "nn.train(method=\"newton\", maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.287629165161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28762916516131887"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork(hidden_size=25, output_size=10)\n",
    "nn.fit(X, y)\n",
    "nn.set_params(theta1_loaded, theta2_loaded)\n",
    "nn.cross_entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
